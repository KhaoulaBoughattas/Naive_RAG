# ğŸ“š NaÃ¯ve RAG (Retrieval-Augmented Generation)

## ğŸš€ Introduction
Ce projet implÃ©mente un **pipeline RAG standard (aussi appelÃ© RAG naÃ¯f)**.  
Il sâ€™agit de lâ€™architecture de base pour connecter un **modÃ¨le de langage (LLM)** Ã  une **base documentaire**, afin de gÃ©nÃ©rer des rÃ©ponses **plus fiables et contextualisÃ©es** que celles dâ€™un LLM seul.  

Contrairement aux variantes avancÃ©es (RAG agentique, RAG hybride), ce pipeline est **entiÃ¨rement sÃ©quentiel** :  
- il prend les documents bruts,  
- les transforme en reprÃ©sentations vectorielles,  
- effectue une recherche dense,  
- et injecte le contexte dans le modÃ¨le pour gÃ©nÃ©rer une rÃ©ponse.  

Lâ€™objectif est pÃ©dagogique : comprendre et implÃ©menter les **fondations de RAG** avant dâ€™explorer les amÃ©liorations possibles.  

---

## ğŸ—ï¸ Ã‰tapes dÃ©taillÃ©es du Pipeline

### 1. Acquisition et PrÃ©traitement des DonnÃ©es
- **Sources** : Documents PDF (scientifiques, rapports, manuels).  
- **Extraction** : bibliothÃ¨que [Unstructured](https://github.com/Unstructured-IO/unstructured), qui segmente automatiquement le texte en blocs exploitables.  
- **Nettoyage (`extraction.py`)** :  
  - Suppression des mÃ©tadonnÃ©es (ISBN, Ã©diteurs, dÃ©pÃ´ts lÃ©gaux).  
  - Ã‰limination des numÃ©ros de page, tables des matiÃ¨res et en-tÃªtes/pieds rÃ©pÃ©tÃ©s.  
  - Correction des artefacts dâ€™extraction (`!` â†’ puces, suppression des doublons).  
- **Sortie** : un fichier consolidÃ© `data/texte_nettoye.txt`.  

âš¡ *Pourquoi ?*  
Un texte brut non nettoyÃ© introduit du bruit â†’ embeddings moins prÃ©cis â†’ rÃ©ponses moins fiables.  

---

### 2. Segmentation en *Chunks*
- **Outil** : `RecursiveCharacterTextSplitter` (LangChain).  
- **ParamÃ¨tres choisis** :  
  - Taille des chunks : `512 caractÃ¨res`  
  - Chevauchement : `64 caractÃ¨res`  
- **Pourquoi ces valeurs ?**  
  - 512 caractÃ¨res â‰ˆ 100 tokens â†’ Ã©quilibre entre granularitÃ© et cohÃ©rence.  
  - Overlap = 64 â†’ maintien du contexte entre segments.  
- **Sortie** : fichier JSON contenant les chunks + mÃ©tadonnÃ©es (id, source).  

Exemple dâ€™un chunk :  
```json
{
  "id": "chunk_0042",
  "source": "data/texte_nettoye.txt",
  "content": "Alan Turing est considÃ©rÃ© comme le pÃ¨re de lâ€™informatique moderne...",
  "start": 1500,
  "end": 2012
}
```
# 3. GÃ©nÃ©ration des ReprÃ©sentations Vectorielles (Embeddings)

**ModÃ¨le utilisÃ© :** `intfloat/multilingual-e5-base`  

- Encodeur multilingue performant  
- SpÃ©cialement adaptÃ© au **franÃ§ais** et Ã  lâ€™**anglais**  

## CaractÃ©ristiques
- Vecteurs de dimension **768**  
- Normalisation **L2** activÃ©e â†’ mesure de similaritÃ© **cosinus** stable  
- **Script :** `embed.py`  
- **Sortie :** `chunks_with_embeddings.json`  

## âš¡ Pourquoi ce modÃ¨le ?
- **LÃ©ger (base model)** â†’ rapide Ã  exÃ©cuter  
- **Multilingue** â†’ extensible Ã  plusieurs langues  
- Bonne compatibilitÃ© avec **FAISS** et **Qdrant**  
# 4. Indexation Vectorielle

**Moteurs testÃ©s :**  
- `Qdrant` (par dÃ©faut)  
- `FAISS` (alternative locale)  

## Configuration Qdrant
- **MÃ©trique de distance :** cosinus  
- Collection reconstruite automatiquement si existante  
- **Insertion par lots** (batch size = 200) â†’ Ã©vite surcharge rÃ©seau  
- **Script :** `get_vector_db.py`  

## âš¡ Pourquoi Qdrant ?
- Support natif des recherches **scalables**  
- **API Python moderne**  
- Gestion robuste des **batchs**  

---

# 5. Transformation de la RequÃªte Utilisateur

- La requÃªte est encodÃ©e avec le **mÃªme modÃ¨le dâ€™embedding**  
- Comparaison avec tous les embeddings stockÃ©s via **similaritÃ© cosinus**  

### Exemple de reprÃ©sentation (simplifiÃ©e) :
```python
query_vector = encoder.encode("Qui est Alan Turing?")
similarities = cosine_similarity(query_vector, stored_embeddings)
```
# 6. Recherche Dense et RÃ©cupÃ©ration

- **StratÃ©gie appliquÃ©e :** pure dense retrieval  
- Les **top-k** (par dÃ©faut k=5) chunks les plus proches sont sÃ©lectionnÃ©s  
- Pas de reranking lexical (**BM25**) ni de combinaison hybride  

## âš¡ Avantages
- RapiditÃ©  

## âš¡ Limites
- SensibilitÃ© aux erreurs dâ€™**embedding**  

---

# 7. Fusion et GÃ©nÃ©ration de la RÃ©ponse

- ConcatÃ©nation des chunks sÃ©lectionnÃ©s  
- Injection dans un **LLM :** `qwen2.5` via **Ollama**  

## StratÃ©gie de gÃ©nÃ©ration
- RÃ©ponse **concise**  
- FidÃ¨le aux **documents sources**  

### Exemple :
**Input :**  
Qui est Alan Turing ?
**Output :**  
Alan Turing est un mathÃ©maticien britannique, pionnier de lâ€™informatique et de la cryptanalyse.
Il est notamment connu pour sa contribution au dÃ©cryptage dâ€™Enigma et pour le test de Turing.
# ğŸ§© Architecture Globale

Le pipeline repose sur **3 couches principales** :  

1. **Ingestion & prÃ©paration des donnÃ©es**  
   - Extraction PDF, nettoyage, segmentation  

2. **Stockage & recherche vectorielle**  
   - Embeddings multilingues  
   - Qdrant / FAISS  

3. **GÃ©nÃ©ration augmentÃ©e**  
   - Top-k retrieval â†’ injection contexte â†’ LLM  

## Diagramme du pipeline

```mermaid
graph TD
    A[ğŸ“‚ PDF Sources] --> B[ğŸ§¹ Extraction & Nettoyage]
    B --> C[âœ‚ï¸ Chunking]
    C --> D[ğŸ”¢ Embeddings]
    D --> E[ğŸ—„ï¸ Vector DB (Qdrant/FAISS)]
    E --> F[â“ User Query]
    F --> G[ğŸ” SimilaritÃ© Cosinus]
    G --> H[ğŸ“‘ Top-k Chunks]
    H --> I[ğŸ¤– LLM (qwen2.5 via Ollama)]
    I --> J[ğŸ“ RÃ©ponse ContextualisÃ©e]
```
# âš™ï¸ Installation & ExÃ©cution

## 1. Cloner le projet
```bash
git clone https://github.com/username/naive-rag.git
cd naive-rag
```
## 2.Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```
## 3. Lancer une dÃ©mo
```bash
python src/rag.py
```
# ğŸ“ˆ Limites actuelles
- Recherche **purement vectorielle** (pas de BM25 / reranking)  
- Pas de **filtrage dynamique** ni de **context re-ranking**  
- Pas de **self-evaluation** ou correction a posteriori  

---

# ğŸ”® AmÃ©liorations futures
- IntÃ©grer un **retrieval hybride** (dense + lexical)  
- Utiliser un **LLM plus avancÃ©** (Mistral, GPT, Llama 3)  
- Ajouter un **module de feedback utilisateur**  
- ImplÃ©menter un **RAG agentique** (capacitÃ© de raisonnement + actions externes)  

---

# ğŸ‘©â€ğŸ’» Auteur
**Khaoula Boughattas** â€“ Ã‰tudiante en **Data Engineering & Decision Systems**



